---
layout: default
title: Ethical AI
nav_order: 1
description: ""
permalink: /use_cases/ethical_ai
parent: Use Cases
---

# Ethical AI
> ![Workflow](../gifs/ethical_ai.gif)
> The existence of an AI oracle service means that it is possible to have DAO-controlled AI for the first time. Such an implication can fundamentally change we train AI, decentralizing the process. A DAO's governance structure can be leveraged to determine how the AI is trained (model parameters) and on what data (input dataset). One can even take this further and have multiple DAOs coordinate to train a model. This is a step towards democratically constructed datasets and transparently trained models. 

## Example
> Bias in ML is a problem with societal implications. It is possible to mitigate this using a coalition of DAOs to manage training. The DAOs can come to a quorum on an input dataset that they believe to be complete and unbiased, then a Portal training request will verifiably train the model to use this dataset.

> This is a stark contrast to current AI practices, where datasets are siloed, and models are opaque. 

> A concrete example of this process would be for training unbiased facial recognition models. The DAOs in the coalition could represent different ethnic backgrounds. Their responsibility is to ensure that the input dataset covers *all* ethnicities to help mitigate bias in models.


